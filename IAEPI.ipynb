{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python==4.4.0.40 in c:\\programdata\\anaconda3\\lib\\site-packages (4.4.0.40)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from opencv-python==4.4.0.40) (1.19.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python==4.4.0.40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.4.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import zipfile\n",
    "print(cv2.__version__)\n",
    "import winsound\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_path = os.path.sep.join([\"obj.names\"])\n",
    "LABELS = open(labels_path).read().strip().split(\"\\n\")\n",
    "weights_path = os.path.sep.join([\"yolov4_custom_final.weights\"])\n",
    "config_path = os.path.sep.join([\"yolov4_custom.cfg\"])\n",
    "\n",
    "net = cv2.dnn.readNet(config_path, weights_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "COLORS = np.random.randint(0, 255, size=(len(LABELS), 3), dtype=\"uint8\")\n",
    "\n",
    "ln = net.getLayerNames()\n",
    "#print(\"Todas as camadas (layers):\")\n",
    "#print(ln)\n",
    "#print(\"Total: \"+ str(len(ln)))\n",
    "#print(\"Camadas de saÃ­da: \")\n",
    "#print(net.getUnconnectedOutLayers())\n",
    "ln = [ln[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "#print(ln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostrar(img):\n",
    "  fig = plt.gcf()\n",
    "  fig.set_size_inches(16, 10)\n",
    "  plt.axis(\"off\")\n",
    "  plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blob_imagem(net, imagem, mostrar_texto=True):\n",
    "  inicio = time.time() \n",
    "  blob = cv2.dnn.blobFromImage(imagem, 1 / 255.0, (416, 416), swapRB=True, crop=False)\n",
    "  net.setInput(blob)\n",
    "  layerOutputs = net.forward(ln)\n",
    "  termino = time.time()\n",
    "  #if mostrar_texto:\n",
    "    #print(\"YOLO levou {:.2f} segundos\".format(termino - inicio))\n",
    "  return net, imagem, layerOutputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deteccoes(detection, _threshold, caixas, confiancas, IDclasses):\n",
    "  scores = detection[5:] \n",
    "  classeID = np.argmax(scores)  \n",
    "  confianca = scores[classeID]\n",
    "\n",
    "  if confianca > _threshold:\n",
    "      caixa = detection[0:4] * np.array([W, H, W, H])     \n",
    "      (centerX, centerY, width, height) = caixa.astype(\"int\")\n",
    "            \n",
    "      x = int(centerX - (width / 2))\n",
    "      y = int(centerY - (height / 2))\n",
    "\n",
    "      caixas.append([x, y, int(width), int(height)])\n",
    "      confiancas.append(float(confianca))\n",
    "      IDclasses.append(classeID)\n",
    "      \n",
    "  return caixas, confiancas, IDclasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def funcoes_imagem(imagem, i, confiancas, caixas, COLORS, LABELS, mostrar_texto=True):  \n",
    "  (x, y) = (caixas[i][0], caixas[i][1])\n",
    "  (w, h) = (caixas[i][2], caixas[i][3])\n",
    "\n",
    "  cor = [int(c) for c in COLORS[IDclasses[i]]]\n",
    "  cv2.rectangle(imagem, (x, y), (x + w, y + h), cor, 2) \n",
    "  texto = \"{}: {:.4f}\".format(LABELS[IDclasses[i]], confiancas[i])\n",
    "  if mostrar_texto:\n",
    "    print(\"> \" + texto)\n",
    "    print(x,y,w,h)\n",
    "  cv2.putText(imagem, texto, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, cor, 2)\n",
    "\n",
    "  return imagem,x,y,w,h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivo_video = 0\n",
    "cap = cv2.VideoCapture(arquivo_video)\n",
    "conectado, video = cap.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conectado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(640, 480)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_largura = video.shape[1]\n",
    "video_altura = video.shape[0]\n",
    "video_largura, video_altura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def redimensionar(largura, altura, largura_maxima = 600): \n",
    "  if (largura > largura_maxima):\n",
    "    proporcao = largura / altura\n",
    "    video_largura = largura_maxima\n",
    "    video_altura = int(video_largura / proporcao)\n",
    "  else:\n",
    "    video_largura = largura\n",
    "    video_altura = altura\n",
    "\n",
    "  return video_largura, video_altura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "threshold_NMS = 0.3\n",
    "fonte_pequena, fonte_media = 0.4, 0.6\n",
    "fonte = cv2.FONT_HERSHEY_SIMPLEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terminou\n"
     ]
    }
   ],
   "source": [
    "classes = [\"Helmet\",\"Clothing\",\"Glasses\"]\n",
    "while (cv2.waitKey(10) < 0):\n",
    "  conectado, frame = cap.read()\n",
    "  if not conectado:\n",
    "    break\n",
    "  t = time.time()\n",
    "  frame = cv2.resize(frame, (video_largura, video_altura))\n",
    "  try:\n",
    "    (H, W) = frame.shape[:2]\n",
    "  except:\n",
    "    print('Erro')\n",
    "    continue\n",
    "\n",
    "  imagem_cp = frame.copy() \n",
    "  net, frame, layerOutputs = blob_imagem(net, frame)\n",
    "  caixas = []       \n",
    "  confiancas = []   \n",
    "  IDclasses = []    \n",
    "\n",
    "  for output in layerOutputs:\n",
    "    for detection in output:\n",
    "      caixas, confiancas, IDclasses = deteccoes(detection, threshold, caixas, confiancas, IDclasses)\n",
    "\n",
    "  objs = cv2.dnn.NMSBoxes(caixas, confiancas, threshold, threshold_NMS)\n",
    "\n",
    "  if len(objs) > 0:\n",
    "    for i in objs.flatten():\n",
    "          frame, x, y, w, h = funcoes_imagem(frame, i, confiancas, caixas, COLORS, LABELS, mostrar_texto=False)\n",
    "          objeto = imagem_cp[y:y + h, x:x + w]\n",
    "        \n",
    "          if LABELS[IDclasses[i]] == \"Helmet\":  \n",
    "            cv2.putText(frame, \"COM CAPACETE\", \n",
    "            (20, video_altura-400), fonte, 1, (200, 50, 250), 2, lineType=cv2.LINE_AA) \n",
    "                    \n",
    "  \n",
    "  cv2.putText(frame, \"frame processado em {:.2f} segundos\".format(time.time() - t), \n",
    "             (20, video_altura-20), fonte, fonte_pequena, (250, 250, 250), 0, lineType=cv2.LINE_AA)\n",
    "\n",
    "  #if len(objs) == 0:\n",
    "      #  cv2.putText(frame, \"SEM CAPACETE\", \n",
    "       # (20, video_altura-400), fonte, 1, (0, 50, 250), 2, lineType=cv2.LINE_AA)     \n",
    " \n",
    "  cv2.imshow(\"tela\",frame)\n",
    "\n",
    "print('Terminou') \n",
    " \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
